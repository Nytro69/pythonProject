{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12e71e75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12e71e75",
        "outputId": "38ab6540-767a-46b3-ec3e-b4f2970cd865"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 113MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 3.43MB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 58.0MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"fashion\",\n",
        "    train=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"fashion\",\n",
        "    train=False,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "\n",
        "train_dataload, test_dataload = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True), torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "train_features, train_labels = next(iter(train_dataload))\n",
        "test_features, test_labels = next(iter(test_dataload))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f0e7373",
      "metadata": {
        "id": "0f0e7373"
      },
      "outputs": [],
      "source": [
        "class MNIST(nn.Module):\n",
        "    def __init__(self, input_size=784, output_size=10, hidden_size=128):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.stack = nn.Sequential(\n",
        "            nn.Linear(in_features=input_size, out_features=hidden_size),\n",
        "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
        "            nn.Linear(in_features=hidden_size, out_features=output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.stack(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19475bea",
      "metadata": {
        "id": "19475bea"
      },
      "outputs": [],
      "source": [
        "model = MNIST().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZZJgZaoF9crb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZJgZaoF9crb",
        "outputId": "d59d5c70-ecf7-46d3-e91e-c2c37542166e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading helper_functions.py\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85bc3bb2",
      "metadata": {
        "id": "85bc3bb2"
      },
      "outputs": [],
      "source": [
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "964c2252",
      "metadata": {
        "id": "964c2252"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "\n",
        "def time_fn(start, end):\n",
        "    return print(f\"Time to train: {end - start:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d16cb4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d16cb4d",
        "outputId": "86b983ea-866c-4fe2-dbd8-2f737e175897"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 - Batch: 0 - Loss: 2.3230\n",
            "Epoch: 0 - Batch: 100 - Loss: 0.6336\n",
            "Epoch: 0 - Batch: 200 - Loss: 0.7441\n",
            "Epoch: 0 - Batch: 300 - Loss: 0.4377\n",
            "Epoch: 0 - Batch: 400 - Loss: 0.4664\n",
            "Epoch: 0 - Batch: 500 - Loss: 0.4939\n",
            "Epoch: 0 - Batch: 600 - Loss: 0.4149\n",
            "Epoch: 0 - Batch: 700 - Loss: 0.4340\n",
            "Epoch: 0 - Batch: 800 - Loss: 0.3453\n",
            "Epoch: 0 - Batch: 900 - Loss: 0.4244\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 1/3 [00:10<00:20, 10.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5532 - Test Loss: 0.5089 - Test Accuracy: 82.31%\n",
            "Epoch: 1 - Batch: 0 - Loss: 0.5370\n",
            "Epoch: 1 - Batch: 100 - Loss: 0.4101\n",
            "Epoch: 1 - Batch: 200 - Loss: 0.3658\n",
            "Epoch: 1 - Batch: 300 - Loss: 0.3172\n",
            "Epoch: 1 - Batch: 400 - Loss: 0.2524\n",
            "Epoch: 1 - Batch: 500 - Loss: 0.4046\n",
            "Epoch: 1 - Batch: 600 - Loss: 0.2123\n",
            "Epoch: 1 - Batch: 700 - Loss: 0.5523\n",
            "Epoch: 1 - Batch: 800 - Loss: 0.4022\n",
            "Epoch: 1 - Batch: 900 - Loss: 0.4557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 2/3 [00:19<00:09,  9.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4576 - Test Loss: 0.4781 - Test Accuracy: 83.36%\n",
            "Epoch: 2 - Batch: 0 - Loss: 0.4570\n",
            "Epoch: 2 - Batch: 100 - Loss: 0.7887\n",
            "Epoch: 2 - Batch: 200 - Loss: 0.3016\n",
            "Epoch: 2 - Batch: 300 - Loss: 0.4094\n",
            "Epoch: 2 - Batch: 400 - Loss: 0.3842\n",
            "Epoch: 2 - Batch: 500 - Loss: 0.5246\n",
            "Epoch: 2 - Batch: 600 - Loss: 0.3014\n",
            "Epoch: 2 - Batch: 700 - Loss: 0.5198\n",
            "Epoch: 2 - Batch: 800 - Loss: 0.3065\n",
            "Epoch: 2 - Batch: 900 - Loss: 0.5907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:29<00:00,  9.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4400 - Test Loss: 0.4710 - Test Accuracy: 83.45%\n",
            "Time to train: 29.318 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "\n",
        "start_time = timeit.default_timer()\n",
        "\n",
        "\n",
        "\n",
        "for epoch in tqdm.tqdm(range(epochs)):\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(train_dataload):\n",
        "        model.train()\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        y_pred = model(X)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print(f\"Epoch: {epoch} - Batch: {batch} - Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_loss /= len(train_dataload)\n",
        "\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in test_dataload:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            test_pred = model(X)\n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "        test_loss /= len(test_dataload)\n",
        "        test_acc /= len(test_dataload)\n",
        "        print(f\"Train Loss: {train_loss:.4f} - Test Loss: {test_loss:.4f} - Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "end_time = timeit.default_timer()\n",
        "\n",
        "time_fn(start_time, end_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "172c8e43",
      "metadata": {
        "id": "172c8e43"
      },
      "outputs": [],
      "source": [
        "def model_evaluation(\n",
        "        dataloader,\n",
        "        model,\n",
        "        loss_fn,\n",
        "        accuracy_fn,\n",
        "        device=device\n",
        "        ):\n",
        "\n",
        "    loss, acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            loss += loss_fn(pred, y)\n",
        "            acc += accuracy_fn(y_true=y, y_pred=pred.argmax(dim=1))\n",
        "        loss /= len(dataloader)\n",
        "        acc /= len(dataloader)\n",
        "\n",
        "    return {\n",
        "        \"model\": model.__class__.__name__,\n",
        "        \"loss\": loss.item(),\n",
        "        \"accuracy\": acc\n",
        "    }\n",
        "\n",
        "model_results = model_evaluation(model=model,\n",
        "                              dataloader=test_dataload,\n",
        "                              loss_fn=loss_fn,\n",
        "                              accuracy_fn=accuracy_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BMGnjaC6-VOe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMGnjaC6-VOe",
        "outputId": "5e8e45c6-5c94-4262-ce48-96d6b2b59f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Jul 24 22:14:06 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0             31W /   70W |     160MiB /  15360MiB |      2%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LegI4qprBSqJ",
      "metadata": {
        "id": "LegI4qprBSqJ"
      },
      "outputs": [],
      "source": [
        "class MNIST1(nn.Module):\n",
        "    def __init__(self, input_size=784, output_size=10, hidden_size=128):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.stack = nn.Sequential(\n",
        "            nn.Linear(in_features=input_size, out_features=hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_size, out_features=output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.stack(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P2HoPvyHBZf8",
      "metadata": {
        "id": "P2HoPvyHBZf8"
      },
      "outputs": [],
      "source": [
        "model_1 = MNIST1().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1areNTn6YShU",
      "metadata": {
        "id": "1areNTn6YShU"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model_1.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1BXY21peYyjt",
      "metadata": {
        "id": "1BXY21peYyjt"
      },
      "outputs": [],
      "source": [
        "def train_step(model,\n",
        "               loss_fn,\n",
        "               optimizer,\n",
        "               train_dataloader,\n",
        "               device=device,\n",
        "               accuracy_fn=accuracy_fn\n",
        "               ):\n",
        "\n",
        "    train_loss, train_acc = 0, 0\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "        model.train()\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        y_pred = model(X)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss\n",
        "        train_acc += accuracy_fn(y_pred=y_pred.argmax(dim=1), y_true=y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 500 == 0:\n",
        "          print(f\"{batch*train_dataloader.batch_size}/{train_dataloader.batch_size*len(train_dataloader)} samples\")\n",
        "\n",
        "    train_loss /= len(train_dataloader)\n",
        "    train_acc /= len(train_dataloader)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.5f} - Train Accuracy: {train_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JyRFlmXUomC5",
      "metadata": {
        "id": "JyRFlmXUomC5"
      },
      "outputs": [],
      "source": [
        "def test_step(\n",
        "    model,\n",
        "    loss_fn,\n",
        "    test_dataloader,\n",
        "    device=device,\n",
        "    accuracy_fn=accuracy_fn\n",
        "    ):\n",
        "\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "        for X, y in test_dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            test_pred = model(X)\n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "        test_loss /= len(test_dataload)\n",
        "        test_acc /= len(test_dataload)\n",
        "        print(f\"Train Loss: {train_loss:.4f} - Test Loss: {test_loss:.4f} - Test Accuracy: {test_acc:.3f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f34721f8",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JBUg15xdreyM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JBUg15xdreyM",
        "outputId": "748cae1e-c5e3-4f98-e229-26bbf8237b64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0/60032 samples\n",
            "32000/60032 samples\n",
            "Train Loss: 0.54045 - Train Accuracy: 80.769\n",
            "Train Loss: 0.4400 - Test Loss: 0.4393 - Test Accuracy: 83.877%\n",
            "0/60032 samples\n",
            "32000/60032 samples\n",
            "Train Loss: 0.37804 - Train Accuracy: 86.267\n",
            "Train Loss: 0.4400 - Test Loss: 0.3958 - Test Accuracy: 85.768%\n",
            "0/60032 samples\n",
            "32000/60032 samples\n",
            "Train Loss: 0.33839 - Train Accuracy: 87.555\n",
            "Train Loss: 0.4400 - Test Loss: 0.3606 - Test Accuracy: 87.361%\n"
          ]
        }
      ],
      "source": [
        "for _ in range(3):\n",
        "  train_step(\n",
        "      model=model_1,\n",
        "      loss_fn=loss_fn,\n",
        "      train_dataloader=train_dataload,\n",
        "      optimizer=optimizer\n",
        "  )\n",
        "  test_step(\n",
        "      model=model_1,\n",
        "      loss_fn=loss_fn,\n",
        "      test_dataloader=test_dataload\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ihKfJErbA8N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ihKfJErbA8N",
        "outputId": "27e1fdb2-3910-4580-d1cf-0805b93a5660"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model': 'MNIST1', 'loss': 0.47096750140190125, 'accuracy': 83.44944267515923}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1_results = model_evaluation(model=model_1,\n",
        "                              dataloader=test_dataload,\n",
        "                              loss_fn=loss_fn,\n",
        "                              accuracy_fn=accuracy_fn)\n",
        "\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AjHGuKHNjPwt",
      "metadata": {
        "id": "AjHGuKHNjPwt"
      },
      "outputs": [],
      "source": [
        "class MNIST2(nn.Module):\n",
        "  def __init__(self, input_units, hidden_units, output_units):\n",
        "      super().__init__()\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.conv_block_1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=input_units, out_channels=hidden_units, kernel_size=3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2)\n",
        "          )\n",
        "\n",
        "      self.conv_block_2 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2)\n",
        "          )\n",
        "      self.classifier = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(in_features=hidden_units*7*7, out_features=output_units)\n",
        "      )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv_block_2(self.conv_block_1(x))\n",
        "    x = self.classifier(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P9l5H2n0o-Sy",
      "metadata": {
        "id": "P9l5H2n0o-Sy"
      },
      "outputs": [],
      "source": [
        "model_2 = MNIST2(input_units=1, hidden_units=10, output_units=10).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_2.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xJqQVZw2ftuE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJqQVZw2ftuE",
        "outputId": "8719ed82-4a9e-4a30-cc80-5de2a51174c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0/60032 samples\n",
            "32000/60032 samples\n",
            "Train Loss: 0.32590 - Train Accuracy: 88.225\n",
            "Train Loss: 0.4400 - Test Loss: 0.3415 - Test Accuracy: 87.609%\n",
            "0/60032 samples\n",
            "32000/60032 samples\n",
            "Train Loss: 0.30625 - Train Accuracy: 88.884\n",
            "Train Loss: 0.4400 - Test Loss: 0.3203 - Test Accuracy: 88.346%\n",
            "0/60032 samples\n",
            "32000/60032 samples\n",
            "Train Loss: 0.29037 - Train Accuracy: 89.366\n",
            "Train Loss: 0.4400 - Test Loss: 0.3122 - Test Accuracy: 88.744%\n",
            "0/60032 samples\n",
            "32000/60032 samples\n",
            "Train Loss: 0.27817 - Train Accuracy: 89.895\n",
            "Train Loss: 0.4400 - Test Loss: 0.3003 - Test Accuracy: 89.441%\n",
            "0/60032 samples\n",
            "32000/60032 samples\n",
            "Train Loss: 0.26719 - Train Accuracy: 90.239\n",
            "Train Loss: 0.4400 - Test Loss: 0.2928 - Test Accuracy: 89.640%\n",
            "0/60032 samples\n",
            "32000/60032 samples\n",
            "Train Loss: 0.25843 - Train Accuracy: 90.607\n",
            "Train Loss: 0.4400 - Test Loss: 0.2982 - Test Accuracy: 89.451%\n",
            "0/60032 samples\n",
            "32000/60032 samples\n",
            "Train Loss: 0.25074 - Train Accuracy: 90.827\n",
            "Train Loss: 0.4400 - Test Loss: 0.3065 - Test Accuracy: 89.013%\n",
            "0/60032 samples\n",
            "32000/60032 samples\n",
            "Train Loss: 0.24255 - Train Accuracy: 91.225\n",
            "Train Loss: 0.4400 - Test Loss: 0.2930 - Test Accuracy: 89.242%\n",
            "0/60032 samples\n",
            "32000/60032 samples\n",
            "Train Loss: 0.23717 - Train Accuracy: 91.240\n",
            "Train Loss: 0.4400 - Test Loss: 0.2838 - Test Accuracy: 90.157%\n",
            "0/60032 samples\n",
            "32000/60032 samples\n",
            "Train Loss: 0.23342 - Train Accuracy: 91.466\n",
            "Train Loss: 0.4400 - Test Loss: 0.2795 - Test Accuracy: 89.998%\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(10):\n",
        "  train_step(\n",
        "      model=model_2,\n",
        "      loss_fn=loss_fn,\n",
        "      train_dataloader=train_dataload,\n",
        "      optimizer=optimizer\n",
        "  )\n",
        "  test_step(\n",
        "      model=model_2,\n",
        "      loss_fn=loss_fn,\n",
        "      test_dataloader=test_dataload\n",
        "  )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
